---
title: "fin"
author:
  - name: "Mtro. Santiago Ríos"
    email: santiagoboo99@gmail.com
    affiliation: 
      - name: Cursos Orca
        city: CDMX
        url: orcaasesina.com
format: 
    live-html:
        highlightStyle: github
        highlightLines: true
        theme: superhero
toc: true
sidebar: false
# webr:
#     packages: 
#         - datos
#         - dplyr
#         - tidyr
#         - ggplot2
#     render-df: gt-interactive
engine: knitr
---

<!-- {{< include ../_extensions/r-wasm/live/_knitr.qmd >}} -->



### Regresión Lineal Simple y Validación Cruzada

La **regresión lineal simple** es una técnica estadística que se utiliza para modelar la relación entre dos variables continuas. El objetivo es predecir los valores de una variable dependiente (Y) con base en los valores de una variable independiente (X), usando una ecuación lineal de la forma:

$$ Y = \beta_0 + \beta_1X + \epsilon $$

Donde:
- \( Y \) es la variable dependiente.
- \( X \) es la variable independiente.
- \( \beta_0 \) es la intersección (el valor de \( Y \) cuando \( X = 0 \)).
- \( \beta_1 \) es la pendiente (el cambio en \( Y \) por cada unidad de cambio en \( X \)).
- \( \epsilon \) es el término de error (la diferencia entre los valores observados y los predichos).

#### Validación Cruzada del Modelo

La validación cruzada es una técnica utilizada para evaluar la capacidad de un modelo de generalizarse a muestras diferentes. Es decir, se busca comprobar si el modelo puede predecir correctamente en un conjunto diferente de datos, más allá de la muestra con la que se entrenó.

Existen dos métodos principales para realizar la validación cruzada en un modelo de regresión lineal:

1. **R² Ajustado**:
   - El valor de \( R^2 \) ajustado corrige el valor de \( R^2 \) para evitar el sobreajuste, que ocurre cuando el modelo se ajusta demasiado bien a los datos de la muestra, pero no generaliza bien a otros datos.
   - Mientras que \( R^2 \) indica cuánta varianza de la variable dependiente \( Y \) es explicada por el modelo en la muestra de datos, el \( R^2 \) ajustado nos da una idea de cuánta varianza sería explicada si el modelo hubiera sido derivado de la población completa.
   - En R, el \( R^2 \) ajustado se calcula automáticamente cuando se ajusta un modelo de regresión lineal con la función `lm()`.

2. **División de Datos**:
   - Este enfoque implica dividir el conjunto de datos en dos partes: una muestra de entrenamiento (generalmente el 80%) y una muestra de prueba (el 20% restante).
   - Se ajusta el modelo de regresión en la muestra de entrenamiento y se valida en la muestra de prueba. Luego, se comparan los coeficientes y el \( R^2 \) entre ambas muestras para ver cuán bien se generaliza el modelo original.
   - Este método es especialmente útil cuando se utilizan técnicas de regresión escalonada, ya que permite evaluar si el modelo es robusto y estable en diferentes subconjuntos de los datos.

### Ejemplo en R utilizando `tidyverse`

A continuación, te muestro cómo realizar una validación cruzada simple usando los dos métodos mencionados: \( R^2 \) ajustado y división de datos, utilizando un conjunto de datos de ejemplo.

#### 1. Calcular el \( R^2 \) ajustado

Primero, ajustamos un modelo de regresión y obtenemos el \( R^2 \) ajustado.

```r
# Cargar las librerías necesarias
library(tidyverse)

# Crear un conjunto de datos de ejemplo
set.seed(123)
datos <- tibble(
  x = rnorm(100, mean = 50, sd = 10),
  y = 2 * x + rnorm(100, mean = 0, sd = 5)
)

# Ajustar el modelo de regresión lineal
modelo <- lm(y ~ x, data = datos)

# Resumen del modelo para obtener el R² ajustado
summary(modelo)$adj.r.squared
```

En este código:
- Creamos un conjunto de datos con 100 observaciones.
- Ajustamos un modelo de regresión lineal simple para predecir `y` en función de `x`.
- Obtenemos el valor de \( R^2 \) ajustado usando `summary(modelo)$adj.r.squared`.

#### 2. Validación cruzada usando división de datos

Ahora, realizamos la división de los datos en entrenamiento y prueba, y comparamos los resultados.

```r
# Dividir los datos en un 80% de entrenamiento y 20% de prueba
set.seed(123)
datos_divididos <- datos %>%
  mutate(split = sample(c("train", "test"), n(), replace = TRUE, prob = c(0.8, 0.2)))

# Separar los conjuntos de entrenamiento y prueba
datos_train <- datos_divididos %>% filter(split == "train")
datos_test <- datos_divididos %>% filter(split == "test")

# Ajustar el modelo en el conjunto de entrenamiento
modelo_train <- lm(y ~ x, data = datos_train)

# Predecir en el conjunto de prueba
predicciones_test <- predict(modelo_train, newdata = datos_test)

# Calcular el R² en el conjunto de prueba
r2_test <- cor(predicciones_test, datos_test$y)^2
r2_test
```

En este código:
- Dividimos los datos en un 80% de conjunto de entrenamiento y un 20% de conjunto de prueba.
- Ajustamos el modelo de regresión en el conjunto de entrenamiento.
- Usamos el conjunto de prueba para predecir y luego calculamos el \( R^2 \) en los datos de prueba para evaluar la capacidad del modelo de generalizarse a nuevos datos.

### Conclusión

- El \( R^2 \) ajustado nos da una idea de qué tan bien se podría comportar el modelo en la población completa.
- La división de datos es una técnica más robusta que permite evaluar la capacidad predictiva del modelo en un conjunto de datos completamente diferente, lo que da una mejor idea sobre la generalización del modelo.

Ambos métodos son esenciales para evaluar la calidad de un modelo de regresión y asegurar que no esté sobreajustado a los datos de entrenamiento.